loading config
init logging
init model
init dataset (the first time this will take a while)
init trainer
starting training
âœ… Saved user embeddings to /var/scratch/zta207/experiments/mind_small_CL_embedding/before_cl_user_emb.csv

 Epoch 0:
training:
saving checkpoint
test iteration in CL trainer
[Epoch 0] total: 0.1580, rec: 0.1470, cl: 1.1044
testing:
test iteration in contrastive ranking trainer
saving scores
[Epoch CL 0] test loss: 0.0984, ndcg@5: 0.3441, ndcg@10: 0.4063, mrr: 0.3604, ctr@1: 0.1887, auc: 0.6595, acc: 0.8981, rec: 0.0184, prec: 0.0192

 Epoch 1:
training:
saving checkpoint
test iteration in CL trainer
[Epoch 1] total: 0.1516, rec: 0.1425, cl: 0.9181
testing:
test iteration in contrastive ranking trainer
saving scores
[Epoch CL 1] test loss: 0.1005, ndcg@5: 0.3422, ndcg@10: 0.4046, mrr: 0.3589, ctr@1: 0.1894, auc: 0.6575, acc: 0.8959, rec: 0.0279, prec: 0.0291

 Epoch 2:
training:
saving checkpoint
test iteration in CL trainer
[Epoch 2] total: 0.1495, rec: 0.1412, cl: 0.8281
testing:
test iteration in contrastive ranking trainer
saving scores
[Epoch CL 2] test loss: 0.1011, ndcg@5: 0.3489, ndcg@10: 0.4125, mrr: 0.3654, ctr@1: 0.1909, auc: 0.6640, acc: 0.8957, rec: 0.0365, prec: 0.0380

 Epoch 3:
training:
saving checkpoint
test iteration in CL trainer
[Epoch 3] total: 0.1479, rec: 0.1403, cl: 0.7565
testing:
test iteration in contrastive ranking trainer
saving scores
[Epoch CL 3] test loss: 0.1014, ndcg@5: 0.3585, ndcg@10: 0.4213, mrr: 0.3736, ctr@1: 0.1987, auc: 0.6758, acc: 0.8940, rec: 0.0458, prec: 0.0460

 Epoch 4:
training:
